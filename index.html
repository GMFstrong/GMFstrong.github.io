<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>ConqUeroR</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="From Zero to the DevOps">
<meta property="og:type" content="website">
<meta property="og:title" content="ConqUeroR">
<meta property="og:url" content="http://gmfdevops.com.com/index.html">
<meta property="og:site_name" content="ConqUeroR">
<meta property="og:description" content="From Zero to the DevOps">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ConqUeroR">
<meta name="twitter:description" content="From Zero to the DevOps">
  
    <link rel="alternative" href="/atom.xml" title="ConqUeroR" type="application/atom+xml">
  
  
    <link rel="icon" href="http://7xkj1z.com1.z0.glb.clouddn.com/head.jpg">
  
  <link rel="stylesheet" href="/css/style.css">
  
  

  <script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>
  <script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>

  
      <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
<script>AV.initialize("your_app_id", "your_app_key");</script>
<script src="/js/Counter.js"></script>
  
</head>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1530275036756&amp;di=fbef4a64ede1f8237b28de7618e9a502&amp;imgtype=0&amp;src=http%3A%2F%2Ftx.haiqq.com%2Fuploads%2Fallimg%2F170507%2F0Q25BU9-8.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">ConqUeroR</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						<li>友情链接</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/categories/websec">Web安全</a></li>
				        
							<li><a href="/categories/linux">Linux基础</a></li>
				        
							<li><a href="/categories/linux-ser1">Linux服务</a></li>
				        
							<li><a href="/categories/linux-ser2">Linux集群</a></li>
				        
							<li><a href="/categories/shell">Shell编程</a></li>
				        
							<li><a href="/categories/python">Python脚本</a></li>
				        
							<li><a href="/categories/network">网络配置</a></li>
				        
							<li><a href="/categories/other">其它</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://github.com/smackgg/hexo-theme-smackdown">smackdown</a>
			        
			        </div>
				</section>
				

				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">ConqUeroR</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1530275036756&amp;di=fbef4a64ede1f8237b28de7618e9a502&amp;imgtype=0&amp;src=http%3A%2F%2Ftx.haiqq.com%2Fuploads%2Fallimg%2F170507%2F0Q25BU9-8.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">ConqUeroR</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/categories/websec">Web安全</a></li>
		        
					<li><a href="/categories/linux">Linux基础</a></li>
		        
					<li><a href="/categories/linux-ser1">Linux服务</a></li>
		        
					<li><a href="/categories/linux-ser2">Linux集群</a></li>
		        
					<li><a href="/categories/shell">Shell编程</a></li>
		        
					<li><a href="/categories/python">Python脚本</a></li>
		        
					<li><a href="/categories/network">网络配置</a></li>
		        
					<li><a href="/categories/other">其它</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap">
  
    <article id="post-ELK安装及配置" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/01/04/ELK安装及配置/" class="article-date">
  	<time datetime="2020-01-04T05:00:09.000Z" itemprop="datePublished">2020-01-04</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/04/ELK安装及配置/">
        ELK安装及配置
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>1) 安装elasticsearch：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">1.准备环境，安装并配置(elasticsearch的安装包分为带JDK与不带JDK的)：</span><br><span class="line">    mkdir /data/elasticsearch/&#123;data,log&#125; -pv</span><br><span class="line">    dpkg -i /usr/local/src/elasticsearch-7.5.1-amd64.deb</span><br><span class="line">    chown elasticsearch:elasticsearch -R /data/elasticsearch/</span><br><span class="line"></span><br><span class="line">    vim /etc/elasticsearch/elasticsearch.yml  #修改以下几行</span><br><span class="line">        cluster.name: gmf-elk</span><br><span class="line">        node.name: node-1</span><br><span class="line">        path.data: /data/elasticsearch/data</span><br><span class="line">        path.logs: /data/elasticsearch/log</span><br><span class="line">        network.host: 192.168.38.212</span><br><span class="line">        http.port: 9200</span><br><span class="line">        discovery.seed_hosts: [&quot;192.168.38.212&quot;, &quot;192.168.38.213&quot;]</span><br><span class="line">        cluster.initial_master_nodes: [&quot;192.168.38.212&quot;, &quot;192.168.38.213&quot;]</span><br><span class="line"></span><br><span class="line">    systemctl restart elasticsearch.service</span><br><span class="line">    访问 192.168.38.&#123;212|213&#125;:9200 看web页面是否正常。</span><br><span class="line"></span><br><span class="line">2.安装elasticsearch-head（web插件用于管理查看elasticsearch）：</span><br><span class="line">    apt-get -y install apt-transport-https ca-certificates curl software-properties-common</span><br><span class="line">    add-apt-repository &quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;</span><br><span class="line">    apt-get -y update</span><br><span class="line">    apt-get -y install docker-ce=5:18.09.9~3-0~ubuntu-bionic</span><br><span class="line">    docker pull mobz/elasticsearch-head:5</span><br><span class="line">    docker run -d -p 9100:9100 mobz/elasticsearch-head:5</span><br><span class="line"></span><br><span class="line">    vim /etc/elasticsearch/elasticsearch.yml  #在各个elasticsearch节点开启http的管理权限</span><br><span class="line">        http.cors.enabled: true</span><br><span class="line">        http.cors.allow-origin: &quot;*&quot;</span><br><span class="line">    systemctl restart elasticsearch</span><br><span class="line"></span><br><span class="line">3.安装cerebro(web管理查看elasticsearch):</span><br><span class="line">    sed -i &quot;s@http://.*archive.ubuntu.com@http://mirrors.huaweicloud.com@g&quot; /etc/apt/sources.list &amp;&amp; \</span><br><span class="line">    sed -i &quot;s@http://.*security.ubuntu.com@http://mirrors.huaweicloud.com@g&quot; /etc/apt/sources.list &amp;&amp; apt update</span><br><span class="line"></span><br><span class="line">    apt install -y openjdk-8-jdk</span><br><span class="line">    mkdir /apps/cerebro -pv</span><br><span class="line">    tar -xvf cerebro-0.8.5.tgz -C /apps/cerebro</span><br><span class="line">    vim /apps/cerebro/cerebro-0.8.5/conf/application.conf</span><br><span class="line">        hosts = [</span><br><span class="line">            &#123;</span><br><span class="line">                host = &quot;http://192.168.38.212:9200&quot;</span><br><span class="line">                name = &quot;GMF-elk cluster&quot;</span><br><span class="line">            #  headers-whitelist = [ &quot;x-proxy-user&quot;, &quot;x-proxy-roles&quot;, &quot;X-Forwarded-For&quot; ]</span><br><span class="line">            &#125;</span><br><span class="line">    /apps/cerebro/cerebro-0.8.5/bin/cerebro</span><br><span class="line">    访问 http://192.168.38.211:9000</span><br><span class="line">4.锁定内存的使用量（及在服务启动时直接注册一定量的内存到内核，提升性能）：</span><br><span class="line">    vim /etc/elasticsearch/elasticsearch.yml</span><br><span class="line">        bootstrap.memory_lock: true</span><br><span class="line">    vim /usr/lib/systemd/system/elasticsearch.service</span><br><span class="line">        LimitMEMLOCK=infinity</span><br></pre></td></tr></table></figure>
<blockquote>
<p>2) 安装配置logstash：</p>
</blockquote>
<p><strong><em><a href="https://www.elastic.co/guide/en/kibana/7.5/managing-indices.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/7.5/managing-indices.html</a></em></strong></p>
<p><strong><em><a href="https://www.elastic.co/guide/en/logstash/current/index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/current/index.html</a></em></strong>   #logstash的插件配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">1.安装：</span><br><span class="line">    apt install -y openjdk-8-jdk</span><br><span class="line">    dpkg -i /usr/local/src/logstash-7.5.1.deb</span><br><span class="line"></span><br><span class="line">2.测试logstash的使用（在屏幕实现标准输入输出）：</span><br><span class="line">    /usr/share/logstash/bin/logstash -e &apos;input &#123; stdin&#123;&#125; &#125; output &#123; stdout&#123; codec =&gt; rubydebug &#125;&#125;&apos;</span><br><span class="line">        成功标志：[INFO ] 2020-01-03 14:27:28.183 [Api Webserver] agent - Successfully started Logstash API endpoint &#123;:port=&gt;9600&#125;</span><br><span class="line"></span><br><span class="line">3.测试logstash写入文件：</span><br><span class="line">    /usr/share/logstash/bin/logstash -e &apos;input &#123; stdin&#123;&#125; &#125; output &#123; file &#123; path =&gt; &quot;/tmp/gmf_test.txt&quot;&#125;&#125;&apos;</span><br><span class="line"></span><br><span class="line">4.测试logstash写入elasticsearch：</span><br><span class="line">    /usr/share/logstash/bin/logstash -e &apos;input &#123; stdin&#123;&#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; [&quot;192.168.38.212:9200&quot;]&#125;&#125;&apos;</span><br><span class="line"></span><br><span class="line">5.基于日志文件输入，输出到elasticsearch保存日志：</span><br><span class="line">    vim /etc/logstash/conf.d/gmf-1.conf</span><br><span class="line">        input &#123;</span><br><span class="line">            file &#123;</span><br><span class="line">                path =&gt; &quot;/var/log/syslog&quot;</span><br><span class="line">                stat_interval =&gt; 2</span><br><span class="line">                start_position =&gt; &quot;beginning&quot;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        output &#123;</span><br><span class="line">            elasticsearch &#123;</span><br><span class="line">                hosts =&gt; [&quot;192.168.38.212:9200&quot;]</span><br><span class="line">                index =&gt; &quot;gmf-test1-syslog-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/gmf-1.conf -t   #测试配置文件是否报错。</span><br><span class="line">    /usr/share/logstash/bin/logstash -f  /etc/logstash/conf.d/gmf-1.conf</span><br><span class="line"></span><br><span class="line">6.更改启动用户，防止因搜集日志时因没有读权限而报错：</span><br><span class="line">    vim /etc/systemd/system/logstash.service</span><br><span class="line">        User=root</span><br><span class="line">        Group=root</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>3) Kibana的安装及配置：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.安装配置：</span><br><span class="line">    dpkg -i /usr/local/src/kibana-7.5.1-amd64.deb </span><br><span class="line">    root@els-2:~# grep ^[a-Z] /etc/kibana/kibana.yml</span><br><span class="line">        server.port: 5601</span><br><span class="line">        server.host: &quot;192.168.38.213&quot;</span><br><span class="line">        server.name: &quot;GMF-ELK&quot;</span><br><span class="line">        elasticsearch.hosts: [&quot;http://192.168.38.212:9200&quot;]</span><br><span class="line">        i18n.locale: &quot;zh-CN&quot;</span><br><span class="line">    systemctl restart kibana.service</span><br></pre></td></tr></table></figure>
<blockquote>
<p>4) logstash的常用配置项：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    file &#123;</span><br><span class="line">        path =&gt; &quot;/var/log/syslog&quot;</span><br><span class="line">        stat_interval =&gt; 2</span><br><span class="line">        start_position =&gt; &quot;beginning&quot;</span><br><span class="line">        type =&gt; &quot;syslog&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    file &#123;</span><br><span class="line">        path =&gt; &quot;/var/log/kern.log&quot;</span><br><span class="line">        stat_interval =&gt; 2</span><br><span class="line">        start_position =&gt; &quot;beginning&quot;</span><br><span class="line">        type =&gt; &quot;kern.log&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  if [type] == &quot;syslog&quot; &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [&quot;192.168.38.212:9200&quot;]</span><br><span class="line">        index =&gt; &quot;gmf-test1-syslog-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line"> &#125;</span><br><span class="line">  if [type] == &quot;kern.log&quot; &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [&quot;192.168.38.212:9200&quot;]</span><br><span class="line">        index =&gt; &quot;gmf-test1-kern.log-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">#       stdout&#123;</span><br><span class="line">#               codec =&gt; &quot;rubydebug&quot;</span><br><span class="line">#       &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/other/">other</a>
	</div>


      
        
<div class="counter-tag counter">
    <span id="/2020/01/04/ELK安装及配置/" class="leancloud_visitors post-title-link"
          style="font-size: 12px" data-flag-title="ELK安装及配置">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-RabbitMQ消息队列" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/12/30/RabbitMQ消息队列/" class="article-date">
  	<time datetime="2019-12-30T09:00:09.000Z" itemprop="datePublished">2019-12-30</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/30/RabbitMQ消息队列/">
        RabbitMQ消息队列
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>1) 安装单机RabbitMQ：（生产 4C 8G）</p>
</blockquote>
<p><strong><em>在使用负载均衡代理时用TCP模式，因为RabbitMQ使用的是专有的七层协议。</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">1.更改主机名，并配置主机名解析（RabbitMQ对主机名的要求比较高）</span><br><span class="line">    hostnamectl set-hostname mq1.gmf.com</span><br><span class="line">    vim /etc/hosts</span><br><span class="line">        192.168.38.207 mq1.gmf.com mq1</span><br><span class="line">2.安装RabbitMQ:</span><br><span class="line">    curl -fsSL https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc | sudo apt-key add -</span><br><span class="line">    apt-key adv --keyserver &quot;hkps.pool.sks-keyservers.net&quot; --recv-keys &quot;0x6B73A36E6026DFCA&quot;</span><br><span class="line">    apt-get install apt-transport-https  #安装 apt HTTPS 传输</span><br><span class="line">    vim /etc/apt/sources.list</span><br><span class="line">        deb https://dl.bintray.com/rabbitmq-erlang/debian bionic erlang</span><br><span class="line">        deb https://dl.bintray.com/rabbitmq/debian bionic main</span><br><span class="line">    apt update </span><br><span class="line">    apt-cache madison rabbitmq-server</span><br><span class="line">    apt install -y rabbitmq-server=3.7.23-1</span><br><span class="line">3.开启web界面管理插件：</span><br><span class="line">    rabbitmq-plugins enable rabbitmq_management</span><br><span class="line"></span><br><span class="line">5672：消费者访问的 端口</span><br><span class="line">15672：web 管理端口</span><br><span class="line">25672：集群状态通信端口</span><br><span class="line"></span><br><span class="line">4.启用guest用户的外部访问：</span><br><span class="line">    vim /usr/lib/rabbitmq/lib/rabbitmq_server-3.7.23/ebin/rabbit.app</span><br><span class="line">        &#123;loopback_users, []&#125;  #39行</span><br><span class="line">    systemctl restart rabbitmq-server.service</span><br><span class="line">5.添加用户：</span><br><span class="line">     rabbitmqctl add_user gmf testroot</span><br><span class="line">     rabbitmqctl set_permissions gmf &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>2) RabbitMQ的集群搭建：</p>
</blockquote>
<p><strong><em>普通集群模式（默认模式）：该模式下，消息实体仅仅存在于其中一个节点，其它节点只有元数据（队列结构），但是消费者在任意节点都可以取到消息实体，因为消息实体可以从存放消息实体的节点传递到消费者访问的节点上。故而消息实体仅仅有一份，存在因单点故障丢数据的风险</em></strong></p>
<p><strong><em>镜像集群模式：该模式解决了单点故障数据丢失的问题，因为消息实体会主动在各个节点间做数据同步。该模式的缺点也不言而喻，随着节点和消息队列数量的增加，必然会引起因数据同步造成集群内部网络带宽的消耗和机器性能的下降。该模式在数据可靠性要求较高时适用。</em></strong></p>
<p><strong><em>在RabbitMQ中存在两种模式的节点：（1）磁盘节点，用于永久保存数据，防止集群因外部因素（机房断电）造成的数据丢失。（2）内存节点，因为磁盘IO较慢，故而采用内存提升速度。</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">1.更改hosts解析：</span><br><span class="line">    vim /etc/hosts</span><br><span class="line">        192.168.38.207 mq1.gmf.com mq1</span><br><span class="line">        192.168.38.208 mq2.gmf.com mq2</span><br><span class="line">        192.168.38.210 mq3.gmf.com mq3</span><br><span class="line">2.更改主机名：</span><br><span class="line">    hostnamectl set-hostname mq1.gmf.com</span><br><span class="line">    hostnamectl set-hostname mq2.gmf.com</span><br><span class="line">    hostnamectl set-hostname mq3.gmf.com</span><br><span class="line">3.在各个节点安装RabbitMQ</span><br><span class="line">    参考单机模式。</span><br><span class="line">4.创建Erlang集群（RabbitMQ集群依赖）：</span><br><span class="line">    systemctl stop rabbitmq-server.service  #关闭各个节点服务</span><br><span class="line">    scp /var/lib/rabbitmq/.erlang.cookie 192.168.38.208:/var/lib/rabbitmq/.erlang.cookie</span><br><span class="line">    scp /var/lib/rabbitmq/.erlang.cookie 192.168.38.210:/var/lib/rabbitmq/.erlang.cookie</span><br><span class="line">    必须保证各节点 cookie 保持一致，文件是 400 的权限，否则节点之间就无法通信。</span><br><span class="line">    systemctl start rabbitmq-server.service</span><br><span class="line">5.将node2和nide3加入node1：</span><br><span class="line">    1.关闭应用服务：</span><br><span class="line">        rabbitmqctl stop_app </span><br><span class="line">    2.清空节点元数据：</span><br><span class="line">        rabbitmqctl reset</span><br><span class="line">    3.将node2和node3以内存节点加入node1(mq1)：</span><br><span class="line">         rabbitmqctl join_cluster rabbit@mq1 --ram #默认为磁盘节点</span><br><span class="line">    4.启动app服务：</span><br><span class="line">        rabbitmqctl start_app</span><br><span class="line">    5.开启各个节点的web管理：</span><br><span class="line">        rabbitmq-plugins enable rabbitmq_management</span><br><span class="line">    6.验证当前集群状态：</span><br><span class="line">        rabbitmqctl cluster_status </span><br><span class="line">            Cluster status of node rabbit@mq1 ...</span><br><span class="line">            [&#123;nodes,[&#123;disc,[rabbit@mq1]&#125;,&#123;ram,[rabbit@mq3,rabbit@mq2]&#125;]&#125;,</span><br><span class="line">            &#123;running_nodes,[rabbit@mq3,rabbit@mq2,rabbit@mq1]&#125;,</span><br><span class="line">            &#123;cluster_name,&lt;&lt;&quot;rabbit@mq1.gmf.com&quot;&gt;&gt;&#125;,</span><br><span class="line">            &#123;partitions,[]&#125;,</span><br><span class="line">            &#123;alarms,[&#123;rabbit@mq3,[]&#125;,&#123;rabbit@mq2,[]&#125;,&#123;rabbit@mq1,[]&#125;]&#125;]</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>3) 将集群配置为镜像模式：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在任意节点执行：</span><br><span class="line">    rabbitmqctl set_policy ha-all &quot;#&quot; &apos;&#123;&quot;ha-mode&quot;:&quot;all&quot;&#125;&apos;</span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/linux-ser2/">linux-ser2</a>
	</div>


      
        
<div class="counter-tag counter">
    <span id="/2019/12/30/RabbitMQ消息队列/" class="leancloud_visitors post-title-link"
          style="font-size: 12px" data-flag-title="RabbitMQ消息队列">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-分布式消息队列Kafka安装与配置" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/12/29/分布式消息队列Kafka安装与配置/" class="article-date">
  	<time datetime="2019-12-29T12:00:10.000Z" itemprop="datePublished">2019-12-29</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/29/分布式消息队列Kafka安装与配置/">
        分布式消息队列Kafka安装与配置
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>1) 安装Kafaka：</p>
</blockquote>
<p><strong><em>kafka依赖于ZooKeeper集群，先安装ZooKeeper集群。</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">wget http://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.3.1/kafka_2.12-2.3.1.tgz</span><br><span class="line">mkdir /apps/kafka</span><br><span class="line">tar -xvf /usr/local/src/kafka_2.12-2.3.1.tgz -C /apps/kafka/</span><br><span class="line">ln -sv /apps/kafka/kafka_2.12-2.3.1/ /usr/local/kafka</span><br><span class="line">mkdir /data/kafka/kafka-logs -pv</span><br><span class="line">vim /usr/local/kafka/config/server.properties</span><br><span class="line">    broker.id=207                               #kafka集群中独一无二</span><br><span class="line">    listeners=PLAINTEXT://192.168.38.207:9092   #监听的地址端口</span><br><span class="line">    log.dirs=/data/kafka/kafka-logs             #消息存放的位置</span><br><span class="line">    zookeeper.connect=192.168.38.207:2181,192.168.38.210:2181,192.168.38.208:2181  #连接的zk的地址,zk中存储了broker的元数据信息</span><br><span class="line">    zookeeper.connection.timeout.ms=10000       #必要时调大超时时间</span><br><span class="line">/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties    #前台启动</span><br><span class="line">        [2020-01-01 14:40:10,758] INFO [KafkaServer id=207] started (kafka.server.KafkaServer)  #启动正常</span><br><span class="line">/usr/local/kafka/bin/kafka-server-start.sh -daemon  #后台启动</span><br><span class="line">tail -f /usr/local/kafka/logs/*                 #查看是否启动成功</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>2) 创建一个topic:</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/kafka/bin/kafka-topics.sh --create --zookeeper 192.168.38.207 --partitions 3 --replication-factor 3 --topic gmf</span><br><span class="line">    Created topic gmf.</span><br><span class="line">/usr/local/kafka/bin/kafka-topics.sh --describe --zookeeper 192.168.38.207 --topic gmf </span><br><span class="line">    Topic:gmf       PartitionCount:3        ReplicationFactor:3     Configs:</span><br><span class="line">        Topic: gmf      Partition: 0    Leader: 207     Replicas: 207,208,210   Isr: 207,208,210</span><br><span class="line">        Topic: gmf      Partition: 1    Leader: 208     Replicas: 208,210,207   Isr: 208,210,207</span><br><span class="line">        Topic: gmf      Partition: 2    Leader: 210     Replicas: 210,207,208   Isr: 210,207,208</span><br></pre></td></tr></table></figure>
<blockquote>
<p>3) 获取所有的Topic：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/kafka/bin/kafka-topics.sh --list --zookeeper 192.168.38.207</span><br></pre></td></tr></table></figure>
<blockquote>
<p>4) 向一个队列里边发送消息：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/kafka/bin/kafka-console-producer.sh --broker-list 192.168.38.207:9092 --topic gmf</span><br></pre></td></tr></table></figure>
<blockquote>
<p>5) 获取消息：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/kafka/bin/kafka-console-consumer.sh --topic gmf --bootstrap-server 192.168.38.207:9092 --from-beginning</span><br></pre></td></tr></table></figure>
<blockquote>
<p>6) 删除一个topic:</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/kafka/bin/kafka-topics.sh --delete --zookeeper 192.168.38.207 --topic gmf</span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/linux-ser2/">linux-ser2</a>
	</div>


      
        
<div class="counter-tag counter">
    <span id="/2019/12/29/分布式消息队列Kafka安装与配置/" class="leancloud_visitors post-title-link"
          style="font-size: 12px" data-flag-title="分布式消息队列Kafka安装与配置">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-ZooKeeper的安装配置" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/12/29/ZooKeeper的安装配置/" class="article-date">
  	<time datetime="2019-12-29T12:00:09.000Z" itemprop="datePublished">2019-12-29</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/29/ZooKeeper的安装配置/">
        ZooKeeper的安装配置
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>1) 安装单机的ZooKeeper：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">1.安装JDK环境：</span><br><span class="line">    apt install -y openjdk-8-jdk</span><br><span class="line">2.安装ZooKeeper:</span><br><span class="line">    mkdir /apps/zookeeper -pv</span><br><span class="line">    cd /apps/zookeeper</span><br><span class="line">    wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz</span><br><span class="line">    tar -xvf zookeeper-3.4.14.tar.gz</span><br><span class="line">    cp zoo_sample.cfg zoo.cfg</span><br><span class="line">3.配置文件介绍：</span><br><span class="line">    tickTime=2000 #服务器与服务器之间的单次心跳检测时间间隔，单位为毫秒</span><br><span class="line"></span><br><span class="line">    initLimit=10 #集群中 leader 服务器与 follower 服务器初始连接心跳次数，即多少个 2000 毫秒，在网络不好时调大。</span><br><span class="line"></span><br><span class="line">    syncLimit=5 # leader 与 follower 之间连接完成之后，后期检测发送和应答的心跳次数，如果该 follower </span><br><span class="line">    在设置的时间内(5*2000)不能与 leader 进行通信，那么此 follower 将被视为不可用。</span><br><span class="line"></span><br><span class="line">    dataDir=/usr/local/zookeeper/data #自定义的 zookeeper 保存数据的目录。</span><br><span class="line"></span><br><span class="line">    clientPort=2181 #客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。</span><br><span class="line"></span><br><span class="line">    maxClientCnxns=4096 #设置最大连接客户端数量。</span><br><span class="line"></span><br><span class="line">    autopurge.snapRetainCount=128 #设置 zookeeper 保存多少次客户端连接的数据。</span><br><span class="line"></span><br><span class="line">    autopurge.purgeInterval=1 #服务器编号=服务器 IP:LF 数据同步端口:LF 选举端口。</span><br><span class="line"></span><br><span class="line">    server.1=172.18.0.101:2888:3888 # server.服务器编号=服务器 IP:LF 数据同步端口(仅仅出现在leader):LF 选举端口。</span><br><span class="line">    server.2=172.18.0.102:2888:3888</span><br><span class="line">    server.3=172.18.0.103:2888:3888</span><br><span class="line">4.启动ZooKeeper:</span><br><span class="line">    /apps/zookeeper/zookeeper-3.4.14/bin/zkServer.sh start</span><br><span class="line">    /apps/zookeeper/zookeeper-3.4.14/bin/zkServer.sh status</span><br></pre></td></tr></table></figure>
<blockquote>
<p>2) ZooKeeper的集群配置：</p>
</blockquote>
<p><strong><em>这里用3台机器构建一个Zookeeper集群，分别安装JDK环境。</em></strong><br><strong><em>zookeeper 集群特性：整个集群种只要有超过集群数量一半的 zookeeper 工作是正常的，那么整个集群对外就是可用的。</em></strong><br><strong><em>在整个ZooKeeper集群中为了保证数据的一致性，仅有Leader具有写权限。</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">1.在各个节点安装ZooKeeper:</span><br><span class="line">    apt install -y openjdk-8-jdk</span><br><span class="line">    mkdir /apps/zookeeper -pv</span><br><span class="line">    mkdir /data/zookeeper -pv</span><br><span class="line">    cd /apps/zookeeper</span><br><span class="line">    tar -xvf zookeeper-3.4.14.tar.gz</span><br><span class="line">    cd /apps/zookeeper/zookeeper-3.4.14/conf/</span><br><span class="line">    cp zoo_sample.cfg zoo.cfg</span><br><span class="line">    vim zoo.cfg</span><br><span class="line">        tickTime=2000</span><br><span class="line">        initLimit=10</span><br><span class="line">        syncLimit=5</span><br><span class="line">        dataDir=/data/zookeeper</span><br><span class="line">        clientPort=2181</span><br><span class="line">        maxClientCnxns=4096</span><br><span class="line">        server.1=192.168.38.208:2888:3888</span><br><span class="line">        server.2=192.168.38.207:2888:3888</span><br><span class="line">        server.3=192.168.38.210:2888:3888</span><br><span class="line">2.创建节点各自在集群中的ID号：</span><br><span class="line">    echo 1 &gt; /data/zookeeper/myid</span><br><span class="line">    ‘/data/zookeeper/’ 该目录为ZooKeeper的数据目录，‘myid’文件中的ID号必须与配置文件server.1中的一致。</span><br><span class="line">3.启动集群（必须在配置文件中指定的时间内启动所有节点）：</span><br><span class="line">    /apps/zookeeper/zookeeper-3.4.14/bin/zkServer.sh start</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>3) 安装zookeeper 客户端 ZooInspector </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">apt install -y maven </span><br><span class="line">git clone https://github.com/zzhang5/zooinspector.git</span><br><span class="line">cd zooinspector/</span><br><span class="line">mvn clean package（注意翻墙，否者很慢）</span><br><span class="line">chmod +x target/zooinspector-pkg/bin/zooinspector.sh</span><br><span class="line">target/zooinspector-pkg/bin/zooinspector.sh （注意开启X11）</span><br></pre></td></tr></table></figure>
<blockquote>
<p>4) 命令行测试写入数据：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/apps/zookeeper/zookeeper-3.4.14/bin/zkCli.sh -server 192.168.38.207:2181</span><br><span class="line">? 查看支持的命令</span><br><span class="line">create /test &quot;hello&quot; 创建数据</span><br><span class="line">get /test    验证数据</span><br><span class="line">connect 192.168.38.208:2181  到其它节点验证数据是否写入</span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/linux-ser2/">linux-ser2</a>
	</div>


      
        
<div class="counter-tag counter">
    <span id="/2019/12/29/ZooKeeper的安装配置/" class="leancloud_visitors post-title-link"
          style="font-size: 12px" data-flag-title="ZooKeeper的安装配置">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Gitlab的基本使用" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/12/16/Gitlab的基本使用/" class="article-date">
  	<time datetime="2019-12-16T10:00:09.000Z" itemprop="datePublished">2019-12-16</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/16/Gitlab的基本使用/">
        Gitlab的基本使用
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>1) 克隆项目到本地：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">git clone http://192.168.38.207/app1/app1-project.git</span><br><span class="line"></span><br><span class="line">git add ./*             #提交代码到暂存区 </span><br><span class="line">git commit -m &apos;V2&apos;      #提交代码到本地仓库 -m 为备注信息</span><br><span class="line">git push                #提交代码到远程仓库</span><br><span class="line">git pull                #获取代码到本地</span><br><span class="line"></span><br><span class="line">git reset --hard HEAD^  #git版本回滚，HEAD为当前版本，加一个^为上一个，^^为上上一个版本</span><br><span class="line">git reflog              #获取每次提交的 ID，可以使用--hard 根据提交的 ID 进行版本回退</span><br><span class="line">git reset --hard xxxx   #回退到指定 id 的版本</span><br><span class="line">git branch              #查看当前所处的分支</span><br><span class="line">git checkout -b develop #创建并切换到一个新分支</span><br><span class="line">git checkout develop    #切换分支</span><br><span class="line"></span><br><span class="line">git status #查看工作区的状态</span><br></pre></td></tr></table></figure>
<blockquote>
<p>2)  .gitignore的作用及定义：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">文件里面定义了不允许开发上传的文件及目录。</span><br><span class="line"></span><br><span class="line">ignoretest/index.html</span><br><span class="line">test2</span><br><span class="line">pass.txt</span><br></pre></td></tr></table></figure>
<blockquote>
<p>3) 克隆指定分支的项目：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone -b Dev http://192.168.38.207/app1/app1-project.git</span><br></pre></td></tr></table></figure>
<blockquote>
<p>4) gitlab的数据备份及恢复：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1.停止以下两个服务（注意不能全停，因为在备份与恢复过程中需要调用数据库等服务。）：</span><br><span class="line">    gitlab-ctl stop unicorn</span><br><span class="line">    gitlab-ctl stop sidekiq</span><br><span class="line">2.开始备份数据库（在任意目录即可备份当前 gitlab 数据）：</span><br><span class="line">    gitlab-rake gitlab:backup:create</span><br><span class="line"></span><br><span class="line">    数据备份的目录：/var/opt/gitlab/backups</span><br><span class="line">3.启动以上服务：</span><br><span class="line">    gitlab-ctl start</span><br><span class="line">4.数据的还原：</span><br><span class="line">    gitlab-ctl stop unicorn</span><br><span class="line">    gitlab-ctl stop sidekiq</span><br><span class="line">    gitlab-rake gitlab:backup:restore BACKUP=备份文件名</span><br><span class="line">        gitlab-rake gitlab:backup:restore BACKUP=1577260768_2019_12_25_11.11.8</span><br><span class="line">    gitlab-ctl start</span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/linux-ser2/">linux-ser2</a>
	</div>


      
        
<div class="counter-tag counter">
    <span id="/2019/12/16/Gitlab的基本使用/" class="leancloud_visitors post-title-link"
          style="font-size: 12px" data-flag-title="Gitlab的基本使用">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Gitlab的搭建及配置" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/12/16/Gitlab的搭建及配置/" class="article-date">
  	<time datetime="2019-12-16T10:00:08.000Z" itemprop="datePublished">2019-12-16</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/16/Gitlab的搭建及配置/">
        Gitlab的搭建及配置
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>1) 配置清华源进行安装：</p>
</blockquote>
<p><strong><em>在生产环境中，由于数据量比较大，因此在安装前需要将数据目录提前挂载好（在使用存储的情况下。）</em></strong></p>
<p><strong><em>默认的数据目录为：/var/opt/gitlab/</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu/pool/bionic/main/g/gitlab-ce/gitlab-ce_11.11.8-ce.0_amd64.deb</span><br><span class="line">dpkg -i gitlab-ce_11.11.8-ce.0_amd64.deb</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>2) 配置邮件通知：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@gmf:~# grep ^[a-Z] /etc/gitlab/gitlab.rb </span><br><span class="line">external_url &apos;http://192.168.38.207&apos;</span><br><span class="line">gitlab_rails[&apos;gitlab_email_from&apos;] = &apos;996941250@qq.com&apos;</span><br><span class="line">gitlab_rails[&apos;smtp_enable&apos;] = true</span><br><span class="line">gitlab_rails[&apos;smtp_address&apos;] = &quot;smtp.qq.com&quot;</span><br><span class="line">gitlab_rails[&apos;smtp_port&apos;] = 465</span><br><span class="line">gitlab_rails[&apos;smtp_user_name&apos;] = &quot;996941250@qq.com&quot;</span><br><span class="line">gitlab_rails[&apos;smtp_password&apos;] = &quot;ndycpollcffobfci&quot;</span><br><span class="line">gitlab_rails[&apos;smtp_domain&apos;] = &quot;qq.com&quot;</span><br><span class="line">gitlab_rails[&apos;smtp_authentication&apos;] = &quot;login&quot;</span><br><span class="line">gitlab_rails[&apos;smtp_enable_starttls_auto&apos;] = true</span><br><span class="line">gitlab_rails[&apos;smtp_tls&apos;] = true</span><br><span class="line">user[&apos;git_user_email&apos;] = &quot;996941250@qq.com&quot;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>3) 初始化配置：</p>
</blockquote>
<p><strong><em>在初始化配置时，gutlab的Nginx组件会占用80端口，如若80端口被占用会初始化失败。</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">gitlab-ctl reconfigure</span><br><span class="line">初始化成功最后4行：</span><br><span class="line">    Running handlers:</span><br><span class="line">    Running handlers complete</span><br><span class="line">    Chef Client finished, 482/1273 resources updated in 03 minutes 13 seconds</span><br><span class="line">    gitlab Reconfigured!</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>4) gitlab的常用命令：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gitlab-ctl status</span><br><span class="line">gitlab-ctl restart </span><br><span class="line">gitlab-ctl stop </span><br><span class="line">gitlab-ctl start</span><br></pre></td></tr></table></figure>
<blockquote>
<p>5) 配置密码：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">访问external_url &apos;http://192.168.38.207&apos;配置的地址，密码必须为8位以上，默认用户名为root。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>6)关闭账号注册：</p>
</blockquote>
<p><strong><em>默认注册功能是开启的，为了防止产生大量垃圾用户，需关闭注册功能。</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在web页面的设置中关闭 Sign-up restrictions 之后保存。</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>7) 汉化gitlab:</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">https://gitlab.com/xhang/gitlab  --&gt;Repository--&gt;tag</span><br><span class="line">wget https://gitlab.com/xhang/gitlab/-/archive/v12.3.5-zh/gitlab-v12.3.5-zh.tar.gz  （比较大，需要翻墙）</span><br><span class="line">tar -xvf gitlab-v12.3.5_source.tar.gz gitlab/</span><br><span class="line">cp -rp  /opt/gitlab/embedded/service/gitlab-rails/ /usr/local/src/gitlab-rails.bak</span><br><span class="line">cd gitlab</span><br><span class="line">head -1 /opt/gitlab/version-manifest.txt #获取当前版本</span><br><span class="line">git diff v11.11.8 v11.11.8-zh &gt; /usr/local/src/v11.11.8-zh.diff</span><br><span class="line">gitlab-ctl stop</span><br><span class="line">patch -f -d /opt/gitlab/embedded/service/gitlab-rails/ -p1 &lt; /usr/local/src/v11.11.8-zh.diff</span><br><span class="line">gitlab-ctl reconfigure</span><br><span class="line">gitlab-ctl start</span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/linux-ser2/">linux-ser2</a>
	</div>


      
        
<div class="counter-tag counter">
    <span id="/2019/12/16/Gitlab的搭建及配置/" class="leancloud_visitors post-title-link"
          style="font-size: 12px" data-flag-title="Gitlab的搭建及配置">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-K8S通过Ansiable二进制部署" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/12/16/K8S通过Ansiable二进制部署/" class="article-date">
  	<time datetime="2019-12-16T08:28:49.000Z" itemprop="datePublished">2019-12-16</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/16/K8S通过Ansiable二进制部署/">
        K8S通过Ansiable二进制部署
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <img src="/2019/12/16/K8S通过Ansiable二进制部署/K8S-2.png">
<blockquote>
<p>1) 配置基本的ansiable环境：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1.在各个节点安装python2.7环境：</span><br><span class="line">    apt-get install python2.7 -y</span><br><span class="line">    ln -s /usr/bin/python2.7 /usr/bin/python</span><br><span class="line">2.在控制端安装ansible，用于推送各种安装命令：</span><br><span class="line">    apt-get install git python-pip -y</span><br><span class="line">    pip install ansible==2.6.18 netaddr==0.7.19 -i https://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">3.在控制端配置免密钥登录：</span><br><span class="line">    ssh-keygen</span><br><span class="line">    ssh-copy-id 192.168.38.206</span><br><span class="line">    ssh-copy-id 192.168.38.205</span><br><span class="line">    ssh-copy-id 192.168.38.204</span><br><span class="line">    ssh-copy-id 192.168.38.203</span><br><span class="line">    ssh-copy-id 192.168.38.202</span><br></pre></td></tr></table></figure>
<blockquote>
<p>2) 使用github的项目推送K8S:</p>
</blockquote>
<p><strong><em>参考链接：<a href="https://github.com/easzlab/kubeasz/" target="_blank" rel="noopener">https://github.com/easzlab/kubeasz/</a></em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">4.下载工具脚本easzup（用于下载项目源码，二进制文件，离线docker镜像，并将其放入/etc/ansilbe）：</span><br><span class="line">    export release=2.0.3</span><br><span class="line">    curl -C- -fLO --retry 3 https://github.com/easzlab/kubeasz/releases/download/$&#123;release&#125;/easzup</span><br><span class="line">    chmod +x ./easzup</span><br><span class="line">5.更改easzup中的配置下载自己的版本：</span><br><span class="line">    export DOCKER_VER=18.09.9</span><br><span class="line">    export KUBEASZ_VER=2.0.3</span><br><span class="line">    export K8S_BIN_VER=v1.15.5</span><br><span class="line">    export EXT_BIN_VER=0.3.0</span><br><span class="line">    export SYS_PKG_VER=0.3.2</span><br><span class="line">6.下载指定的源码，二进制文件，离线docker镜像：</span><br><span class="line">    ./easzup -D</span><br><span class="line">7.配置集群参数（其它一般保持默认）：</span><br><span class="line">    cd /etc/ansible</span><br><span class="line">    cp example/hosts.multi-node hosts</span><br><span class="line">    修改hosts文件：</span><br><span class="line">    vim hosts </span><br><span class="line">    [etcd]</span><br><span class="line">    192.168.38.205 NODE_NAME=etcd1</span><br><span class="line">    192.168.38.206 NODE_NAME=etcd2</span><br><span class="line">    192.168.38.202 NODE_NAME=etcd3</span><br><span class="line"></span><br><span class="line">    [kube-master]</span><br><span class="line">    192.168.38.206</span><br><span class="line">    192.168.38.205</span><br><span class="line"></span><br><span class="line">    [kube-node]</span><br><span class="line">    192.168.38.203</span><br><span class="line">    192.168.38.204</span><br><span class="line"></span><br><span class="line">    CLUSTER_NETWORK=&quot;calico&quot;</span><br><span class="line"></span><br><span class="line">    SERVICE_CIDR=&quot;10.66.0.0/16&quot;</span><br><span class="line"></span><br><span class="line">    CLUSTER_CIDR=&quot;172.88.0.0/16&quot;</span><br><span class="line"></span><br><span class="line">    NODE_PORT_RANGE=&quot;50000-65000&quot;</span><br><span class="line"></span><br><span class="line">    CLUSTER_DNS_DOMAIN=&quot;gmf.com.&quot;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>4) 使用ansiable推送各个二进制程序到各个节点：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">8.在部署之前确保ansiable能ping同各个子节点：</span><br><span class="line">    ansible all -m ping</span><br><span class="line">9.用ansiable推送各个节点所需的组件：</span><br><span class="line">    ansible-playbook 01.prepare.yml #环境初始化</span><br><span class="line">    ansible-playbook 02.etcd.yml #部署etcd</span><br><span class="line">    ansible-playbook 03.docker.yml #部署docker</span><br><span class="line">    ansible-playbook 04.kube-master.yml #部署k8s master</span><br><span class="line">    ansible-playbook 05.kube-node.yml #部署node</span><br></pre></td></tr></table></figure>
<blockquote>
<p>5) 在节点配置链接harbor：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">10.在各个节点添加harbor的host解析：</span><br><span class="line">    echo &apos;192.168.38.202 harbor.gmf.com&apos; &gt;&gt; /etc/hosts</span><br><span class="line"></span><br><span class="line">11.在各个节点添加harbor的证书：</span><br><span class="line">    mkdir /etc/docker/certs.d/harbor.gmf.com/ -pv</span><br><span class="line">    scp 192.168.38.202:/usr/local/src/harbor/certs/harbor-ca.crt /etc/docker/certs.d/harbor.gmf.com/</span><br></pre></td></tr></table></figure>
<blockquote>
<p>6) 配置calico网络组件：</p>
</blockquote>
<p><strong><em>参考链接：<a href="https://github.com/projectcalico/calico/releases/download/v3.4.4/release-v3.4.4.tgz" target="_blank" rel="noopener">https://github.com/projectcalico/calico/releases/download/v3.4.4/release-v3.4.4.tgz</a></em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">12.将calico镜像推送到仓库：</span><br><span class="line">    </span><br><span class="line">    docker login harbor.gmf.com</span><br><span class="line">    docker tag calico/node:v3.4.4 harbor.gmf.com/k8s/node:v3.4.4</span><br><span class="line">    docker push harbor.gmf.com/k8s/node:v3.4.4</span><br><span class="line">    docker tag calico/cni:v3.4.4 harbor.gmf.com/k8s/cni:v3.4.4</span><br><span class="line">    docker push harbor.gmf.com/k8s/cni:v3.4.4</span><br><span class="line">    docker tag calico/kube-controllers:v3.4.4 harbor.gmf.com/k8s/kube-controllers:v3.4.4</span><br><span class="line">    docker push harbor.gmf.com/k8s/kube-controllers:v3.4.4</span><br><span class="line"></span><br><span class="line">13.更改ansiable的配置文件中的源：</span><br><span class="line">    vim templates/calico-v3.4.yaml.j2</span><br><span class="line">        image: harbor.gmf.com/k8s/cni:v3.4.4</span><br><span class="line">        image: harbor.gmf.com/k8s/node:v3.4.4</span><br><span class="line">        image: harbor.gmf.com/k8s/kube-controllers:v3.4.4</span><br><span class="line"></span><br><span class="line">14.为K8S集群配置网络：</span><br><span class="line">    ansible-playbook 06.network.yml</span><br><span class="line"></span><br><span class="line">15.测试集群容器的网络连通性：</span><br><span class="line">    kubectl run net-test1 --image=alpine --replicas=2 sleep 360000</span><br><span class="line">    kubectl run --generator=run-pod/v1 net-test2 --image=alpine --replicas=2 sleep 360000</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>7) 为集群配置DNS服务：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">16.部署kube-DNS；</span><br><span class="line">    docker load -i k8s-dns-kube-dns-amd64_1.14.13.tar.gz</span><br><span class="line">    docker tag gcr.io/google-containers/k8s-dns-kube-dns-amd64:1.14.13 harbor.gmf.com/k8s/k8s-dns-kube-dns-amd64:1.14.13</span><br><span class="line">    docker push harbor.gmf.com/k8s/k8s-dns-kube-dns-amd64:1.14.13</span><br><span class="line"></span><br><span class="line">    docker load -i  k8s-dns-dnsmasq-nanny-amd64_1.14.13.tar.gz</span><br><span class="line">    docker tag gcr.io/google-containers/k8s-dns-dnsmasq-nanny-amd64:1.14.13 harbor.gmf.com/k8s/k8s-dns-dnsmasq-nanny-amd64:1.14.13</span><br><span class="line">    docker push harbor.gmf.com/k8s/k8s-dns-dnsmasq-nanny-amd64:1.14.13</span><br><span class="line"></span><br><span class="line">    docker load -i k8s-dns-sidecar-amd64_1.14.13.tar.gz</span><br><span class="line">    docker tag gcr.io/google-containers/k8s-dns-sidecar-amd64:1.14.13 harbor.gmf.com/k8s/k8s-dns-sidecar-amd64:1.14.13</span><br><span class="line">    docker push harbor.gmf.com/k8s/k8s-dns-sidecar-amd64:1.14.13</span><br><span class="line">    </span><br><span class="line">    vim kube-dns-gmf.yaml（文件自备，修改以下几行：）</span><br><span class="line">        clusterIP: 10.66.0.2</span><br><span class="line">        image: harbor.gmf.com/k8s/k8s-dns-kube-dns-amd64:1.14.13</span><br><span class="line">        - --domain=gmf.com.</span><br><span class="line">        image: harbor.gmf.com/k8s/k8s-dns-dnsmasq-nanny-amd64:1.14.13</span><br><span class="line">        - --server=/gmf.com/127.0.0.1#10053</span><br><span class="line">        image: harbor.gmf.com/k8s/k8s-dns-sidecar-amd64:1.14.13</span><br><span class="line">        - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.gmf.com,5,SRV</span><br><span class="line">        - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.gmf.com,5,SRV</span><br><span class="line"></span><br><span class="line">17.部署core-DNS（在镜像仓库可直接下载）：</span><br><span class="line">    docker pull coredns/coredns:1.6.5</span><br><span class="line">    docker tag coredns/coredns:1.6.5 harbor.gmf.com/k8s/coredns:1.6.5</span><br><span class="line">    docker push harbor.gmf.com/k8s/coredns:1.6.5</span><br><span class="line">    </span><br><span class="line">    vim coredns-gmf.yaml（文件自备，修改以下几行：）</span><br><span class="line">        kubernetes gmf.com in-addr.arpa ip6.arpa &#123;</span><br><span class="line">        image: harbor.gmf.com/k8s/coredns:1.6.5</span><br><span class="line">        clusterIP: 10.66.0.2</span><br></pre></td></tr></table></figure>
<blockquote>
<p>8) 升级K8S集群的各个组件： </p>
</blockquote>
<p><strong><em>各个组件的二进制地址：<a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.15.md#downloads-for-v1157" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.15.md#downloads-for-v1157</a></em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">18.升级k8s：</span><br><span class="line">root@master1:/usr/local/src/k8s-1.15.7/kubernetes/server/bin# cat upgrade.sh</span><br><span class="line">    #!/bin/bash</span><br><span class="line">    NODE=&apos;192.168.38.203</span><br><span class="line">    192.168.38.204&apos;</span><br><span class="line">    for ip in $&#123;NODE&#125;;do</span><br><span class="line">            ssh root@$&#123;ip&#125; &quot;systemctl stop  kubelet kube-proxy&quot;</span><br><span class="line">            scp kubectl kubelet kube-proxy $&#123;ip&#125;:/opt/kube/bin/</span><br><span class="line">            ssh root@$&#123;ip&#125; &quot;systemctl start  kubelet kube-proxy&quot;</span><br><span class="line">    done</span><br><span class="line"></span><br><span class="line">root@master1:/usr/local/src/k8s-1.15.7/kubernetes/server/bin# vim update-Master.sh</span><br><span class="line">    #!/bin/bash</span><br><span class="line">    MASTER=&apos;192.168.38.206</span><br><span class="line">    192.168.38.205&apos;</span><br><span class="line">    for ip in $&#123;MASTER&#125;;do</span><br><span class="line">            ssh root@$&#123;ip&#125; &quot;systemctl stop kube-controller-manager kube-apiserver kubelet kube-proxy kube-scheduler&quot;</span><br><span class="line">            scp kubectl kubelet kube-proxy kube-scheduler kube-apiserver kube-controller-manager $&#123;ip&#125;:/opt/kube/bin/</span><br><span class="line">            ssh root@$&#123;ip&#125; &quot;systemctl start kube-controller-manager kube-apiserver kubelet kube-proxy kube-scheduler&quot;</span><br><span class="line">    done</span><br></pre></td></tr></table></figure></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/other/">other</a>
	</div>


      
        
<div class="counter-tag counter">
    <span id="/2019/12/16/K8S通过Ansiable二进制部署/" class="leancloud_visitors post-title-link"
          style="font-size: 12px" data-flag-title="K8S通过Ansiable二进制部署">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-K8S的五大组件及adm安装" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/12/12/K8S的五大组件及adm安装/" class="article-date">
  	<time datetime="2019-12-12T12:00:09.000Z" itemprop="datePublished">2019-12-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/12/K8S的五大组件及adm安装/">
        K8S的五大组件及adm安装
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>1) 五大组件及etcd的作用：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">1.Master节点的3大组件：</span><br><span class="line">    APIserver：整个集群的网关（入口），负责认证工作，同时负责接收响应用户的请求，所有其他组件通过它进行交互。</span><br><span class="line">    scheduler：调度器，集群在接到API请求后，根据集群当前资源状态，以及请求的所需资源要求做出合理调度。需要考虑独</span><br><span class="line">               立的和集体的资源需求、服务质量需求、硬件/软件/策略限制、亲和与反亲和规范、数据位置、内部负载接口、</span><br><span class="line">               截止时间等。</span><br><span class="line">    controller：控制器，集群内部的管理控制中心，确保集群始终处于预期的工作状态，负责集群内的 Node、Pod 副本、服务</span><br><span class="line">               端点（Endpoint）、命名空间（Namespace）、服务账号（ServiceAccount）、资源定额（ResourceQuota）的管理，</span><br><span class="line">               在以上资源意外停止服务，控制器负责还原至期望状态。</span><br><span class="line">2.Node节点的两大组件：</span><br><span class="line">    kube-proxy：负责维护各个节点间的pod,service的网络通信，引导访问当前service的请求到正确的pod对象。主要依靠生成的iptables</span><br><span class="line">                或者IPVS规制工作。</span><br><span class="line">    kubelet：工作在Node节点的代理客户端，会在Master注册当前节点并负责监视监视分配给自己节点的pod，主要功能如下：</span><br><span class="line">                （1）向 master 汇报 node 节点的状态信息（cup，内存，磁盘，网络IO的使用情况，便于Master做出合理调度。）</span><br><span class="line">                （2）负责接收APIserver发送的pod配置信息，并确保Pod在当前节点处于期望状态。</span><br><span class="line">                （3）准备 Pod 所需的数据卷，在 node 节点执行容器健康检查。</span><br><span class="line">3.关于etcd:</span><br><span class="line">    用于存储当前集群状态信息，并提供了watch（监听机制），当etcd的键值发生变化时，会主动推送变化到APIserver确保集群的高效协同。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>2) 基于kubeadm安装K8S:</p>
</blockquote>
<p><strong><em>可以通过阿里云的镜像仓库把镜像先提前下载下来，可以避免后期因镜像下载异常而导致 k8s 部署异常。</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">1.安装前准备:</span><br><span class="line">    1.禁用swap,selinux,iptables。</span><br><span class="line">        vim /etc/fstab</span><br><span class="line">            #/swapfile                                 none            swap    sw              0       0</span><br><span class="line">        swapoff -a</span><br><span class="line">    2.准备docker运行环境（注意docker版本，必须被K8S版本支持）。</span><br><span class="line">2.安装Master节点：</span><br><span class="line">    1.安装kubelet kubeadm kubectl：</span><br><span class="line">        apt-get update &amp;&amp; apt-get install -y apt-transport-https</span><br><span class="line">        curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -</span><br><span class="line">        echo &apos;deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main&apos; &gt;&gt; /etc/apt/sources.list</span><br><span class="line">        apt-get update</span><br><span class="line">        apt-cache madison kubectl</span><br><span class="line">        apt-get install -y kubelet=1.16.1-00 kubeadm=1.16.1-00 kubectl=1.16.1-00  #确保版本一致。</span><br><span class="line">    2.基于Keepalived实现双Master高可用：</span><br><span class="line">        apt install -y keepalived</span><br><span class="line">        cp /usr/share/doc/keepalived/samples/keepalived.conf.vrrp /etc/keepalived/keepalived.conf</span><br><span class="line">    3.Master初始化：</span><br><span class="line">        kubeadm config images list --kubernetes-version v1.16.1   #查看需要的镜像有哪些。</span><br><span class="line"></span><br><span class="line">        --apiserver-advertise-address string #API Server 将要监听的监听地址，为本机 IP</span><br><span class="line">        --control-plane-endpoint   #VIP的地址</span><br><span class="line">        --apiserver-bind-port int32 #API Server 绑定的端口,默认为 6443</span><br><span class="line">        --kubernetes-version string #选择 k8s 版本，默认为 stable-1</span><br><span class="line">        --pod-network-cidr #设置 pod ip 地址范围</span><br><span class="line">        --service-cidr #设置 service 网络地址范围</span><br><span class="line">        --service-dns-domain string #设置 k8s 内部域名，默认为 cluster.local，会有相应的 DNS 服务</span><br><span class="line">          (kube-dns/coredns)解析生成的域名记录。</span><br><span class="line">        --image-repository string #设置一个镜像仓库，默认为 k8s.gcr.io</span><br><span class="line"></span><br><span class="line">        kubeadm  init  --apiserver-advertise-address=192.168.38.206 \</span><br><span class="line">                       --control-plane-endpoint=192.168.38.66 \</span><br><span class="line">                       --apiserver-bind-port=6443 \</span><br><span class="line">                       --kubernetes-version=v1.16.1 \</span><br><span class="line">                       --pod-network-cidr=10.10.0.0/16 \</span><br><span class="line">                       --service-cidr=172.66.0.0/16 \</span><br><span class="line">                       --service-dns-domain=gmf.local \</span><br><span class="line">                       --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers</span><br><span class="line"></span><br><span class="line">    4.安装flannel插件：</span><br><span class="line">        wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br><span class="line">        vim kube-flannel.yml</span><br><span class="line">            &quot;Network&quot;: &quot;10.10.0.0/16&quot;   # 和--pod-network-cidr保持一致。</span><br><span class="line">        kubectl apply -f kube-flannel.yml</span><br><span class="line">    5.为集群添加另一个Master:</span><br><span class="line">        docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.16.1    </span><br><span class="line">        docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.16.1</span><br><span class="line">        docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.16.1</span><br><span class="line">        docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.16.1</span><br><span class="line">        docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.15-0</span><br><span class="line">        docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.2</span><br><span class="line">        docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1</span><br><span class="line">        生成一个--certificate-key：</span><br><span class="line">            kubeadm init phase upload-certs --upload-certs</span><br><span class="line"></span><br><span class="line">            kubeadm join 192.168.38.66:6443 --token vohtj2.ggikgjmbrm6tkd3m \</span><br><span class="line">                --discovery-token-ca-cert-hash sha256:1d0956ac42f9eff52f34ab9472c7dca4df153de430b90ac3b57e05e780f67209 \</span><br><span class="line">                --control-plane --certificate-key d8e606d50f404d009fffdde36e0aee7503145f498e9cad1a0468155e47c619e4</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>3) 添加Node节点:</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.在node节点安装kubelet=1.16.1-00 kubeadm=1.16.1-00。</span><br><span class="line">2.添加节点：</span><br><span class="line">    kubeadm join 192.168.38.66:6443 --token vohtj2.ggikgjmbrm6tkd3m \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:1d0956ac42f9eff52f34ab9472c7dca4df153de430b90ac3b57e05e780f67209</span><br></pre></td></tr></table></figure>
<blockquote>
<p>4) kubeadm init初始化流程图：</p>
</blockquote>
<img src="/2019/12/12/K8S的五大组件及adm安装/k8s-1.jpg">

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/other/">other</a>
	</div>


      
        
<div class="counter-tag counter">
    <span id="/2019/12/12/K8S的五大组件及adm安装/" class="leancloud_visitors post-title-link"
          style="font-size: 12px" data-flag-title="K8S的五大组件及adm安装">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Jumpservrer安装配置" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/12/09/Jumpservrer安装配置/" class="article-date">
  	<time datetime="2019-12-09T12:00:09.000Z" itemprop="datePublished">2019-12-09</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/09/Jumpservrer安装配置/">
        Jumpservrer安装配置
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>1) 准备mysql数据库:</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">1.准备镜像：</span><br><span class="line">docker pull mysql:5.6.46</span><br><span class="line"></span><br><span class="line">2.准备配置文件：</span><br><span class="line">mkdir -pv /etc/mysql/mysql.conf.d/</span><br><span class="line">vim /etc/mysql/mysql.conf.d/mysqld.cnf</span><br><span class="line">[mysqld]</span><br><span class="line">pid-file        = /var/run/mysqld/mysqld.pid</span><br><span class="line">socket          = /var/run/mysqld/mysqld.sock</span><br><span class="line">datadir         = /var/lib/mysql</span><br><span class="line">symbolic-links=0</span><br><span class="line">character-set-server=utf8</span><br><span class="line"></span><br><span class="line">mkdir -pv /etc/mysql/conf.d/</span><br><span class="line">vim /etc/mysql/conf.d/mysql.cnf</span><br><span class="line">[mysql]</span><br><span class="line">default-character-set=utf8</span><br><span class="line"></span><br><span class="line">3.创建数据目录，防止容器出现异常，引起jumpserver的数据丢失：</span><br><span class="line">mkdir /data/mysql -p</span><br><span class="line"></span><br><span class="line">4.运行mysql容器：</span><br><span class="line">docker run -it -d -p 3306:3306 -v /etc/mysql/mysql.conf.d/mysqld.cnf:/etc/mysql/mysql.conf.d/mysqld.cnf \</span><br><span class="line">                               -v /etc/mysql/conf.d/mysql.cnf:/etc/mysql/conf.d/mysql.cnf \</span><br><span class="line">                               -v /data/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=&quot;testroot&quot; mysql:5.6.46</span><br><span class="line"></span><br><span class="line">5.进入容器为jumpserver创建数据库并授权：</span><br><span class="line">    create database jumpserver default charset &apos;utf8&apos;;</span><br><span class="line">    grant all on jumpserver.* to &apos;jumpserver&apos;@&apos;192.168.38.%&apos; identified by &apos;testroot&apos;;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>2) 安装redis；</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">apt-cache madison redis</span><br><span class="line">apt install -y redis=5:4.0.9-1ubuntu0.2</span><br><span class="line">修改如下两项：</span><br><span class="line">vim /etc/redis/redis.conf</span><br><span class="line">    bind 192.168.38.205</span><br><span class="line">    requirepass testroot</span><br></pre></td></tr></table></figure>
<blockquote>
<p>3) 启动jumpserver容器：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">1.生成key和token:</span><br><span class="line">    if [ &quot;$SECRET_KEY&quot; = &quot;&quot; ]; then SECRET_KEY=`cat /dev/urandom | tr -dc A-Za-z0-9 | head -c 50`; echo &quot;SECRET_KEY=$SECRET_KEY&quot; &gt;&gt; ~/.bashrc; echo $SECRET_KEY; else echo $SECRET_KEY; fi</span><br><span class="line">    if [ &quot;$BOOTSTRAP_TOKEN&quot; = &quot;&quot; ]; then BOOTSTRAP_TOKEN=`cat /dev/urandom | tr -dc A-Za-z0-9 | head -c 16`; echo &quot;BOOTSTRAP_TOKEN=$BOOTSTRAP_TOKEN&quot; &gt;&gt; ~/.bashrc; echo $BOOTSTRAP_TOKEN; else echo $BOOTSTRAP_TOKEN; fi</span><br><span class="line">2.拉取jumpserver镜像;</span><br><span class="line">    docker pull jumpserver/jms_all:1.4.10</span><br><span class="line">3.启动容器：</span><br><span class="line">docker run --name jms_all -d \</span><br><span class="line">    -v /opt/jumpserver:/opt/jumpserver/data/media \</span><br><span class="line">    -p 80:80 \</span><br><span class="line">    -p 2222:2222 \</span><br><span class="line">    -e SECRET_KEY=aDsuxpjtGZ3YtdMC2S0BYVO85GXDDfd6aM9NANhWraITRWsumH \</span><br><span class="line">    -e BOOTSTRAP_TOKEN=LLfYIMS3Wbj7Vi5e \</span><br><span class="line">    -e DB_HOST=192.168.38.205 \</span><br><span class="line">    -e DB_PORT=3306 \</span><br><span class="line">    -e DB_USER=jumpserver \</span><br><span class="line">    -e DB_PASSWORD=testroot \</span><br><span class="line">    -e DB_NAME=jumpserver \</span><br><span class="line">    -e REDIS_HOST=192.168.38.205 \</span><br><span class="line">    -e REDIS_PORT=6379 \</span><br><span class="line">    -e REDIS_PASSWORD=testroot \</span><br><span class="line">    jumpserver/jms_all:1.4.10</span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/linux-ser1/">linux-ser1</a>
	</div>


      
        
<div class="counter-tag counter">
    <span id="/2019/12/09/Jumpservrer安装配置/" class="leancloud_visitors post-title-link"
          style="font-size: 12px" data-flag-title="Jumpservrer安装配置">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Docker的资源限制" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/12/08/Docker的资源限制/" class="article-date">
  	<time datetime="2019-12-08T12:00:09.000Z" itemprop="datePublished">2019-12-08</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/08/Docker的资源限制/">
        Docker的资源限制
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>1) 关于Linux的OOM机制：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">OOM (Out of Memory Exception,内存溢出，随后系统会开始杀死进程以释放内存，凡是运行在宿主机的进程都有可能被 kill，</span><br><span class="line">linux 会为每个进程算一个分数，最终他会将分数最高的进程 kill，不推荐通过在守护程序或容器上手动设置--oom-score-adj </span><br><span class="line">为极端负数，或通过在容器上设置--oom-kill-disable 来绕过这些安全措施。</span><br><span class="line"></span><br><span class="line">/proc/PID/oom_score_adj #范围为-1000 到 1000，值越高越容易被宿主机 kill，如果将该值设置为-1000，则进程永远不会被宿主机 kernel kill。</span><br><span class="line">/proc/PID/oom_adj #范围为-17 到+15，取值越高越容易被干掉，如果是-17，则表示不能被 kill，该设置参数的存在是为了和旧版本的 Linux 内核兼容。</span><br><span class="line">/proc/PID/oom_score #这个值是系统综合进程的内存消耗量、CPU 时间，(utime + stime)、存活时间(uptime - start time)和 oom_adj 计算出的进程</span><br><span class="line">得分，消耗内存越多得分越高，越容易被宿主机 kernel 强制杀死。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>2) Docker的内存限制：</p>
</blockquote>
<p><strong><em>Docker 可以强制执行硬性内存限制，即只允许容器使用给定的内存大小。Docker 也可以执行非硬性内存限制，即容器可以使用尽可能多的内存，除非内核检测到主机上的内存不够用了。假如一个容器未做内存使用限制，则该容器可以利用到系统内存最大空间，默认创建的容器没有做内存资源限制。</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--oom-score-adj #宿主机 kernel 对进程使用的内存进行评分，评分最高的将被宿主机内核 kill 掉，可以指定一个容器的评分但是不推荐手动指定。</span><br><span class="line">--oom-kill-disable #对某个容器关闭 oom 机制，在已设置-m / - memory 选项的容器上禁用 OOM否者无效。</span><br><span class="line">-m or --memory #容器可以使用的最大内存量，如果设置此选项，则允许的最小存值为 4m （4 兆字节）。</span><br><span class="line">--memory-reservation #允许指定小于--memory 的软限制，在超过该限制后会日志仅仅记录一条警告。</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>3) 内存限制认证：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">1.首先安装压力测试工具：</span><br><span class="line">    docker pull lorel/docker-stress-ng</span><br><span class="line">2.查看帮助：</span><br><span class="line">    docker run -it --rm lorel/docker-stress-ng --help</span><br><span class="line">3.对启动的容器进行内存限制（限制该容器最大使用256m内存）：</span><br><span class="line">    --vm-bytes XXXM 限制一个工作进程最大使用的内存（该工具产生的进程）。</span><br><span class="line">    docker run -it --rm -m 256M lorel/docker-stress-ng --vm 2 --vm-bytes 256M</span><br><span class="line">4.查看限制结果：</span><br><span class="line">    docker stats</span><br><span class="line">5.docker对资源的限制是基于Cgroup实现的，可以在以下命令查看：</span><br><span class="line">    cat /sys/fs/cgroup/memory/docker/容器 ID /memory.limit_in_bytes</span><br><span class="line">6.动态修改内存限制大小：</span><br><span class="line">    通过 echo 命令可以改内存限制的值。</span><br><span class="line">    echo 536870912 &gt; /sys/fs/cgroup/memory/docker/dbebef4bd1896231ee096ba7bb99e14bcb0847f56585aadf4d729e9414ddccaf/memory.limit_in_bytes</span><br></pre></td></tr></table></figure>
<blockquote>
<p>4) 关于CPU的限制：</p>
</blockquote>
<p>CPU 密集型的场景：优先级越低越好，计算密集型任务的特点是要进行大量的计算，消耗 CPU 资源，比如计算圆周率、数据处理、对视频进行高<br>清解码等等，全靠 CPU 的运算能力。</p>
<p>IO 密集型的场景：优先级值高点，涉及到网络、磁盘 IO 的任务都是 IO 密集型任务，这类任务的特点是 CPU 消耗很少，任务的大部分时间都<br>在等待 IO 操作完成（因为 IO 的速度远远低于 CPU 和内存的速度），比如 Web 应用，高并发，数据量大的动态网站来说，数据库应该为 IO<br>密集型。</p>
<p><strong><em>查看磁盘调度算法：</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/block/sda/queue/scheduler</span><br></pre></td></tr></table></figure></p>
<p><strong><em>默认情况下，每个容器对主机 CPU 周期的访问权限是不受限制的。</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--cpus #指定容器可以使用多少可用 CPU 资源，例如，如果主机有两个 CPU，并且设置了--cpus =“1.5”，那么该容器将保证最多可以访问 </span><br><span class="line">1.5 个的 CPU(如果是 4 核 CPU，那么还可以是 4 核心上每核用一点，但是总计是 1.5 核心的CPU)。</span><br><span class="line">--cpuset-cpus #用于指定容器运行的 CPU 编号，也就是我们所谓的绑核</span><br><span class="line">--cpu-shares #用于设置 cfs 中调度的相对最大比例权重,cpu-share 的值越高的容器，将会分得更多的时间片。</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>5) cpu限制测试；</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">1.限制一个docker容器最多用1.5个CUP；</span><br><span class="line">    docker run -it --rm -m 256M --cpus 1.5 lorel/docker-stress-ng --cpu 2 --vm 2 </span><br><span class="line">2.top命令查看（按‘1’键）：</span><br><span class="line">    top - 15:26:08 up 9 min,  2 users,  load average: 3.12, 2.17, 1.16</span><br><span class="line">        Tasks: 184 total,   3 running,  99 sleeping,   0 stopped,   0 zombie</span><br><span class="line">        %Cpu0  : 70.3 us,  0.3 sy,  0.0 ni, 28.7 id,  0.0 wa,  0.0 hi,  0.7 si,  0.0 st</span><br><span class="line">        %Cpu1  :  0.3 us,  3.7 sy,  0.0 ni, 53.5 id, 41.9 wa,  0.0 hi,  0.7 si,  0.0 st</span><br><span class="line">        %Cpu2  :  0.0 us,  2.6 sy,  0.0 ni, 11.3 id, 80.0 wa,  0.0 hi,  6.1 si,  0.0 st</span><br><span class="line">        %Cpu3  : 71.9 us,  0.0 sy,  0.0 ni, 28.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">3.将容器运行在指定的cpu上（在第2和第4核CPU上）：</span><br><span class="line">    docker run -it --rm -m 256M --cpus 1.5 --cpuset-cpus 1,3 lorel/docker-stress-ng --cpu 2 --vm 2</span><br><span class="line">        top - 15:31:03 up 14 min,  2 users,  load average: 3.14, 2.66, 1.66</span><br><span class="line">        Tasks: 186 total,   3 running,  99 sleeping,   0 stopped,   0 zombie</span><br><span class="line">        %Cpu0  :  0.0 us,  0.7 sy,  0.0 ni, 97.3 id,  0.0 wa,  0.0 hi,  2.0 si,  0.0 st</span><br><span class="line">        %Cpu1  : 64.3 us, 10.7 sy,  0.0 ni, 11.0 id, 14.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">        %Cpu2  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">        %Cpu3  : 72.9 us,  1.0 sy,  0.0 ni, 20.5 id,  4.3 wa,  0.0 hi,  1.3 si,  0.0 st</span><br><span class="line">4.对容器使用cpu时间片的比例进行控制：</span><br><span class="line">    docker run -it --rm  --name gmf-test1 --cpu-shares 500 lorel/docker-stress-ng --cpu 2 --vm 2</span><br><span class="line">    docker run -it --rm  --name gmf-test2 --cpu-shares 1000 lorel/docker-stress-ng --cpu 2 --vm 2</span><br><span class="line">    docker stats</span><br><span class="line">        CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT    MEM %               NET I/O             BLOCK I/O           PIDS</span><br><span class="line">        983a9e1523e0        gmf-test1           135.94%             532.8MiB / 3.83GiB   13.59%              726B / 0B           0B / 0B             7</span><br><span class="line">        1631b8cfddc8        gmf-test2           269.80%             533MiB / 3.83GiB     13.59%              726B / 0B           0B / 0B             7</span><br><span class="line">5.可以动态修改容器使用cpu时间片的值：</span><br><span class="line">    echo 2000 &gt; /sys/fs/cgroup/cpu,cpuacct/docker/容器 ID/cpu.shares</span><br><span class="line">    echo 1500 &gt; /sys/fs/cgroup/cpu/docker/1631b8cfddc82495faff2680f13dc0258d6f168a788b176ea13aa277df99d0ee/cpu.shares</span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/other/">other</a>
	</div>


      
        
<div class="counter-tag counter">
    <span id="/2019/12/08/Docker的资源限制/" class="leancloud_visitors post-title-link"
          style="font-size: 12px" data-flag-title="Docker的资源限制">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2020 ConqUeroR
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/smackgg/hexo-theme-smackdown" target="_blank">Smackdown</a>
        </div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="/js/main.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>


  </div>
</body>
</html>